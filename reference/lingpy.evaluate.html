
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>lingpy.evaluate package &#8212; LingPy</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/lingpy.css" type="text/css" />
    
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<link rel="stylesheet" type="text/css" href="_static/handheld.css" media="screen and (max-device-width: 720px)" />
<style>
li.nav-item{display: None!important};
</style>

  </head><body>
<div style="color: black;background-color: white; font-size: 3.2em; text-align: left; padding: 15px 10px 10px 15px">
LingPy
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="../index.html">Home</a> |&nbsp;</li>
	<li><a href="../news.html">News</a> |&nbsp;</li>
	<li><a href="../intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="../examples.html">Examples</a> |&nbsp;</li>
	<li><a href="../tutorial/index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="../docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="modules.html">Reference</a> |&nbsp;</li>
  <li><a href="../download.html">Download</a></li>

        <li class="nav-item nav-item-this"><a href="">lingpy.evaluate package</a></li> 
      </ul>
    </div>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="lingpy-evaluate-package">
<h1>lingpy.evaluate package<a class="headerlink" href="#lingpy-evaluate-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-lingpy.evaluate.acd">
<span id="lingpy-evaluate-acd-module"></span><h2>lingpy.evaluate.acd module<a class="headerlink" href="#module-lingpy.evaluate.acd" title="Permalink to this headline">¶</a></h2>
<p>Evaluation methods for automatic cognate detection.</p>
<dl class="py function">
<dt id="lingpy.evaluate.acd.bcubes">
<code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.acd.</span></code><code class="sig-name descname"><span class="pre">bcubes</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wordlist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cogid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lexstatid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modify_ref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_concept</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.bcubes" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute B-Cubed scores for test and reference datasets.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>lex</strong> : <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingpy.basic.wordlist.Wordlist</span></code></a></p>
<blockquote>
<div><p>A <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingpy.basic.wordlist.Wordlist</span></code></a> class or a daughter class,
(like the <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal notranslate"><span class="pre">LexStat</span></code></a> class used for the
computation). It should have two columns indicating cognate IDs.</p>
</div></blockquote>
<p><strong>gold</strong> : str (default=’cogid’)</p>
<blockquote>
<div><p>The name of the column containing the gold standard cognate
assignments.</p>
</div></blockquote>
<p><strong>test</strong> : str (default=’lexstatid’)</p>
<blockquote>
<div><p>The name of the column containing the automatically implemented cognate
assignments.</p>
</div></blockquote>
<p><strong>modify_ref</strong> : function (default=False)</p>
<blockquote>
<div><p>Use a function to modify the reference. If your cognate identifiers
are numerical, for example, and negative values are assigned as
loans, but you want to suppress this behaviour, just set this
keyword to “abs”, and all cognate IDs will be converted to their
absolute value.</p>
</div></blockquote>
<p><strong>pprint</strong> : bool (default=True)</p>
<blockquote>
<div><p>Print out the results</p>
</div></blockquote>
<p><strong>per_concept</strong> : bool (default=False)</p>
<blockquote>
<div><p>Compute b-cubed scores per concep and not for the whole data in one
piece.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>t</strong> : tuple</p>
<blockquote>
<div><p>A tuple consisting of the precision, the recall, and the harmonic mean
(F-scores).</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#lingpy.evaluate.acd.diff" title="lingpy.evaluate.acd.diff"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diff</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.pairs" title="lingpy.evaluate.acd.pairs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pairs</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>B-Cubed scores were first described by <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Bagga1998"><span class="pre">Bagga1998</span></a></code> as part of an
algorithm. Later on, <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Amigo2009"><span class="pre">Amigo2009</span></a></code> showed that they can also used as
to compare cluster decisions. <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Hauer2011"><span class="pre">Hauer2011</span></a></code> applied the B-Cubed
scores first to the task of automatic cognate detection.</p>
</dd></dl>

<dl class="py function">
<dt id="lingpy.evaluate.acd.diff">
<code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.acd.</span></code><code class="sig-name descname"><span class="pre">diff</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wordlist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cogid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lexstatid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modify_ref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tofile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transcription</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ipa'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concepts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.diff" title="Permalink to this definition">¶</a></dt>
<dd><p>Write differences in classifications on an item-basis to file.</p>
<dl>
<dt>lex<span class="classifier"><a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingpy.compare.lexstat.LexStat</span></code></a></span></dt><dd><p>The <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal notranslate"><span class="pre">LexStat</span></code></a> class used for the
computation. It should have two columns indicating cognate IDs.</p>
</dd>
<dt>gold<span class="classifier">str (default=’cogid’)</span></dt><dd><p>The name of the column containing the gold standard cognate
assignments.</p>
</dd>
<dt>test<span class="classifier">str (default=’lexstatid’)</span></dt><dd><p>The name of the column containing the automatically implemented cognate
assignments.</p>
</dd>
<dt>modify_ref<span class="classifier">function (default=False)</span></dt><dd><p>Use a function to modify the reference. If your cognate identifiers
are numerical, for example, and negative values are assigned as
loans, but you want to suppress this behaviour, just set this
keyword to “abs”, and all cognate IDs will be converted to their
absolute value.</p>
</dd>
<dt>pprint<span class="classifier">bool (default=True)</span></dt><dd><p>Print out the results</p>
</dd>
<dt>filename<span class="classifier">str (default=’’)</span></dt><dd><p>Name of the output file. If not specified, it is identical with the
name of the <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal notranslate"><span class="pre">LexStat</span></code></a>, but with the
extension <code class="docutils literal notranslate"><span class="pre">diff</span></code>.</p>
</dd>
<dt>tofile<span class="classifier">bool (default=True)</span></dt><dd><p>If set to c{False}, no data will be written to file, but instead, the
data will be returned.</p>
</dd>
<dt>transcription<span class="classifier">str (default=”ipa”)</span></dt><dd><p>The file in which the transcriptions are located (should be a string,
no segmentized version, for convenience of writing to file).</p>
</dd>
</dl>
<dl class="field-list">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>t</strong> : tuple</p>
<blockquote>
<div><p>A nested tuple consisting of two further tuples. The first
containing precision, recall, and harmonic mean
(F-scores), the second containing the same values for the pair-scores.</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#lingpy.evaluate.acd.bcubes" title="lingpy.evaluate.acd.bcubes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bcubes</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.pairs" title="lingpy.evaluate.acd.pairs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pairs</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>If the <strong>tofile</strong> option is chosen, the results are written to a specific
file with the extension <code class="docutils literal notranslate"><span class="pre">diff</span></code>. This file contains all cognate sets in
which there are differences between gold standard and test sets. It also
gives detailed information regarding false positives, false negatives, and
the words involved in these wrong decisions.</p>
</dd></dl>

<dl class="py function">
<dt id="lingpy.evaluate.acd.extreme_cognates">
<code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.acd.</span></code><code class="sig-name descname"><span class="pre">extreme_cognates</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wordlist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'extremeid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lumper'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.extreme_cognates" title="Permalink to this definition">¶</a></dt>
<dd><p>Return extreme cognates, either lump all words together or split them.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>wordlist</strong> : ~lingpy.basic.wordlist.Wordlist</p>
<blockquote>
<div><p>A ~lingpy.basic.wordlist.Wordlist object.</p>
</div></blockquote>
<p><strong>ref</strong> : str (default=”extremeid”)</p>
<blockquote>
<div><p>The name of the table in your wordlist to which the new IDs should be
written.</p>
</div></blockquote>
<p><strong>bias</strong> : str (default=”lumper”)</p>
<blockquote>
<div><p>If set to “lumper”, all words with a certain meaning will be given the
same cognate set ID, if set to “splitter”, all will be given a separate
ID.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingpy.evaluate.acd.npoint_ap">
<code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.acd.</span></code><code class="sig-name descname"><span class="pre">npoint_ap</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cognates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.npoint_ap" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the n-point average precision.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scores</strong> : list</p>
<blockquote>
<div><p>The scores of your algorithm for pairwise string comparison.</p>
</div></blockquote>
<p><strong>cognates</strong> : list</p>
<blockquote>
<div><p>The cognate codings of the word pairs you compared. 1 indicates that
the pair is cognate, 0 indicates that it is not cognate.</p>
</div></blockquote>
<p><strong>reverse</strong> : bool (default=False)</p>
<blockquote>
<div><p>The order of your ranking mechanism. If your algorithm yields high
scores for words which are probably cognate, and low scores for
non-cognate words, you should set this keyword to “True”.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This follows the description in <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Kondrak2002"><span class="pre">Kondrak2002</span></a></code>. The n-point average
precision is useful to compare the discriminative force of different
algorithms for string similarity, or to train the parameters of a given
algorithm.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cognates</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.evaluate.acd</span> <span class="kn">import</span> <span class="n">npoint_ap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">npoint_ap</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">cognates</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="lingpy.evaluate.acd.pairs">
<code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.acd.</span></code><code class="sig-name descname"><span class="pre">pairs</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lex</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cogid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lexstatid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modify_ref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_return_string</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.pairs" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute pair scores for the evaluation of cognate detection algorithms.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>lex</strong> : <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingpy.compare.lexstat.LexStat</span></code></a></p>
<blockquote>
<div><p>The <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal notranslate"><span class="pre">LexStat</span></code></a> class used for the
computation. It should have two columns indicating cognate IDs.</p>
</div></blockquote>
<p><strong>gold</strong> : str (default=’cogid’)</p>
<blockquote>
<div><p>The name of the column containing the gold standard cognate
assignments.</p>
</div></blockquote>
<p><strong>test</strong> : str (default=’lexstatid’)</p>
<blockquote>
<div><p>The name of the column containing the automatically implemented cognate
assignments.</p>
</div></blockquote>
<p><strong>modify_ref</strong> : function (default=False)</p>
<blockquote>
<div><p>Use a function to modify the reference. If your cognate identifiers
are numerical, for example, and negative values are assigned as
loans, but you want to suppress this behaviour, just set this
keyword to “abs”, and all cognate IDs will be converted to their
absolute value.</p>
</div></blockquote>
<p><strong>pprint</strong> : bool (default=True)</p>
<blockquote>
<div><p>Print out the results</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>t</strong> : tuple</p>
<blockquote>
<div><p>A tuple consisting of the precision, the recall, and the harmonic mean
(F-scores).</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#lingpy.evaluate.acd.diff" title="lingpy.evaluate.acd.diff"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diff</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.bcubes" title="lingpy.evaluate.acd.bcubes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bcubes</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>Pair-scores can be computed in different ways, with often different
results. This variant follows the description by <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Bouchard-Cote2013"><span class="pre">Bouchard-Cote2013</span></a></code>.</p>
</dd></dl>

<dl class="py function">
<dt id="lingpy.evaluate.acd.partial_bcubes">
<code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.acd.</span></code><code class="sig-name descname"><span class="pre">partial_bcubes</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wordlist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.partial_bcubes" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute B-Cubed scores for test and reference datasets for partial cognate            detection.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>wordlist</strong> : <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal notranslate"><span class="pre">Wordlist</span></code></a></p>
<blockquote>
<div><p>A <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal notranslate"><span class="pre">Wordlist</span></code></a>, or one of it’s daughter
classes (like, e.g., the <a class="reference internal" href="lingpy.compare.html#lingpy.compare.partial.Partial" title="lingpy.compare.partial.Partial"><code class="xref py py-class docutils literal notranslate"><span class="pre">Partial</span></code></a>
class used for computation of partial cognates. It should have two
columns indicating cognate IDs.</p>
</div></blockquote>
<p><strong>gold</strong> : str (default=’cogid’)</p>
<blockquote>
<div><p>The name of the column containing the gold standard cognate
assignments.</p>
</div></blockquote>
<p><strong>test</strong> : str (default=’lexstatid’)</p>
<blockquote>
<div><p>The name of the column containing the automatically implemented cognate
assignments.</p>
</div></blockquote>
<p><strong>pprint</strong> : bool (default=True)</p>
<blockquote>
<div><p>Print out the results</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>t</strong> : tuple</p>
<blockquote>
<div><p>A tuple consisting of the precision, the recall, and the harmonic mean
(F-scores).</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#lingpy.evaluate.acd.bcubes" title="lingpy.evaluate.acd.bcubes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bcubes</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.diff" title="lingpy.evaluate.acd.diff"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diff</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.pairs" title="lingpy.evaluate.acd.pairs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pairs</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>B-Cubed scores were first described by <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Bagga1998"><span class="pre">Bagga1998</span></a></code> as part of an
algorithm. Later on, <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Amigo2009"><span class="pre">Amigo2009</span></a></code> showed that they can also used as
to compare cluster decisions. <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Hauer2011"><span class="pre">Hauer2011</span></a></code> applied the B-Cubed
scores first to the task of automatic cognate detection.</p>
</dd></dl>

<dl class="py function">
<dt id="lingpy.evaluate.acd.random_cognates">
<code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.acd.</span></code><code class="sig-name descname"><span class="pre">random_cognates</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wordlist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'randomid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.random_cognates" title="Permalink to this definition">¶</a></dt>
<dd><p>Populate a wordlist with random cognates for each entry.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ref</strong> : str (default=”randomid”)</p>
<blockquote>
<div><p>Cognate set identifier for the newly created random cognate sets.</p>
</div></blockquote>
<p><strong>bias</strong> : str (default=False)</p>
<blockquote>
<div><p>When set to “lumper” this will tend to create less cognate sets and
larger clusters, when set to “splitter” it will tend to create smaller
clusters.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>When using this method for evaluation, you should be careful to
overestimate the results. The function which creates the random clusters is
based on simple functions for randomization and thus probably</p>
</dd></dl>

</div>
<div class="section" id="module-lingpy.evaluate.alr">
<span id="lingpy-evaluate-alr-module"></span><h2>lingpy.evaluate.alr module<a class="headerlink" href="#module-lingpy.evaluate.alr" title="Permalink to this headline">¶</a></h2>
<p>Module provides methods for the evaluation of automatic linguistic reconstruction analyses.</p>
<dl class="py function">
<dt id="lingpy.evaluate.alr.mean_edit_distance">
<code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.alr.</span></code><code class="sig-name descname"><span class="pre">mean_edit_distance</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wordlist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'proto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'consensus'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cogid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">keywords</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.alr.mean_edit_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Function computes the edit distance between gold standard and test set.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>wordlist</strong> : ~lingpy.basic.wordlist.Wordlist</p>
<blockquote>
<div><p>The wordlist object containing the data for a given analysis.</p>
</div></blockquote>
<p><strong>gold</strong> : str (default=”proto”)</p>
<blockquote>
<div><p>The name of the column containing the gold-standard solutions.</p>
</div></blockquote>
<p><strong>test = “consensus”</strong> :</p>
<blockquote>
<div><p>The name of the column containing the test solutions.</p>
</div></blockquote>
<p><strong>stress</strong> : str (default=rcParams[‘stress’])</p>
<blockquote>
<div><p>A string containing the stress symbols used in the sound-class
conversion. Defaults to the stress as defined in
~lingpy.settings.rcParams.</p>
</div></blockquote>
<p><strong>diacritics</strong> : str (default=rcParams[‘diacritics’])</p>
<blockquote>
<div><p>A string containing diacritic symbols used in the sound-class
conversion. Defaults to the diacritic symbolds defined in
~lingpy.settings.rcParams.</p>
</div></blockquote>
<p><strong>cldf</strong> : bool (default=False)</p>
<blockquote>
<div><p>If set to True, this will allow for a specific treatment of phonetic
symbols which cannot be completely resolved (e.g., laryngeal h₂ in
Indo-European). Following the <a class="reference external" href="http://cldf.clld.org">CLDF</a>
specifications (in particular the specifications for writing
transcriptions in segmented strings, as employed by the <a class="reference external" href="http://calc.digling.org/clts/">CLTS</a> initiative), in cases of insecurity
of pronunciation, users can adopt a <code class="docutils literal notranslate"><span class="pre">`source/target`</span></code> style, where
the source is the symbol used, e.g., in a reconstruction system, and
the target is a proposed phonetic interpretation. This practice is also
accepted by the <a class="reference external" href="http://edictor.digling.org">EDICTOR</a> tool.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>dist</strong> : float</p>
<blockquote>
<div><p>The mean edit distance between gold and test reconstructions.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This function has an alias (“med”). Calling it will produce the same
results.</p>
</dd></dl>

<dl class="py function">
<dt id="lingpy.evaluate.alr.med">
<code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.alr.</span></code><code class="sig-name descname"><span class="pre">med</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wordlist</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">keywords</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.alr.med" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-lingpy.evaluate.apa">
<span id="lingpy-evaluate-apa-module"></span><h2>lingpy.evaluate.apa module<a class="headerlink" href="#module-lingpy.evaluate.apa" title="Permalink to this headline">¶</a></h2>
<p>Basic module for the comparison of automatic phonetic alignments.</p>
<dl class="py class">
<dt id="lingpy.evaluate.apa.Eval">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.apa.</span></code><code class="sig-name descname"><span class="pre">Eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.Eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Base class for evaluation objects.</p>
</dd></dl>

<dl class="py class">
<dt id="lingpy.evaluate.apa.EvalMSA">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.apa.</span></code><code class="sig-name descname"><span class="pre">EvalMSA</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingpy.evaluate.apa.Eval" title="lingpy.evaluate.apa.Eval"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingpy.evaluate.apa.Eval</span></code></a></p>
<p>Base class for the evaluation of automatic multiple sequence analyses.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>gold, test</strong> : <a class="reference internal" href="lingpy.align.html#lingpy.align.sca.MSA" title="lingpy.align.sca.MSA"><code class="xref py py-class docutils literal notranslate"><span class="pre">MSA</span></code></a></p>
<blockquote>
<div><p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">Multiple</span></code> objects which shall be
compared. The first object should be the gold standard and the second
object should be the test set.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Most of the scores which can be calculated with help of this class are standard
evaluation scores in evolutionary biology. For a close description on how
these scores are calculated, see, for example, <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>,
<code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2012"><span class="pre">List2012</span></a></code>, and <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Rosenberg2009b"><span class="pre">Rosenberg2009b</span></a></code>.</p>
<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalMSA.c_score">
<code class="sig-name descname"><span class="pre">c_score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.c_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the column (C) score.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> : { 1, 2, 3, 4 }</p>
<blockquote>
<div><p>Indicate, which mode to compute. Select between:</p>
<ol class="arabic simple">
<li><p>divide the number of common columns in reference and test
alignment by the total number of columns in the test alignment
(the traditional C score described in <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>,
also known as “precision” score in applications of information
retrieval),</p></li>
<li><p>divide the number of common columns in reference and test
alignment by the total number of columns in the reference
alignment (also known as “recall” score in applications of
information retrieval),</p></li>
<li><p>divide the number of common columns in reference and test
alignment by the average number of columns in reference and test
alignment, or</p></li>
<li><p>combine the scores of mode <code class="docutils literal notranslate"><span class="pre">1</span></code> and mode <code class="docutils literal notranslate"><span class="pre">2</span></code> by computing
their F-score, using the formula <img class="math" src="../_images/math/f382f3aceb0b9047525a9bfe2b06fb320284431d.png" alt="2 * \frac{pr}{p+r}"/>,
where <em>p</em> is the precision (mode <code class="docutils literal notranslate"><span class="pre">1</span></code>) and <em>r</em> is the recall
(mode <code class="docutils literal notranslate"><span class="pre">2</span></code>).</p></li>
</ol>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> : float</p>
<blockquote>
<div><p>The C score for reference and test alignments.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The different c-</p>
</dd></dl>

<dl class="py attribute">
<dt id="lingpy.evaluate.apa.EvalMSA.c_scores">
<code class="sig-name descname"><span class="pre">c_scores</span></code><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.c_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the c-scores.</p>
</dd></dl>

<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalMSA.check_swaps">
<code class="sig-name descname"><span class="pre">check_swaps</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.check_swaps" title="Permalink to this definition">¶</a></dt>
<dd><p>Check for possibly identical swapped sites.</p>
<dl class="field-list">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>swap</strong> : { -2, -1, 0, 1, 2 }</p>
<blockquote>
<div><p>Information regarding the identity of swap decisions is coded by
integers, whereas</p>
<dl class="simple">
<dt>1 – indicates that swaps are detected in both gold standard and</dt><dd><p>testset, whereas a negative value indicates that the positions
are not identical,</p>
</dd>
<dt>2 – indicates that swap decisions are not identical in gold</dt><dd><p>standard and testset, whereas a negative value indicates that
there is a false positive in the testset, and</p>
</dd>
<dt>0 – indicates that there are no swaps in the gold standard and the</dt><dd><p>testset.</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalMSA.jc_score">
<code class="sig-name descname"><span class="pre">jc_score</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.jc_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Jaccard (JC) score.</p>
<dl class="field-list">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>score</strong> : float</p>
<blockquote>
<div><p>The JC score.</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">lingpy.test.evaluate.EvalPSA.jc_score</span></code></p>
</div>
<p class="rubric">Notes</p>
<p>The Jaccard score (see <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2012"><span class="pre">List2012</span></a></code>) is calculated by dividing the size of
the intersection of residue pairs in reference and test alignment by
the size of the union of residue pairs in reference and test alignment.</p>
</dd></dl>

<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalMSA.r_score">
<code class="sig-name descname"><span class="pre">r_score</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.r_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the rows (R) score.</p>
<dl class="field-list">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>score</strong> : float</p>
<blockquote>
<div><p>The PIR score.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The R score is the number of identical rows (sequences) in reference and test
alignment divided by the total number of rows.</p>
</dd></dl>

<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalMSA.sp_score">
<code class="sig-name descname"><span class="pre">sp_score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.sp_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the sum-of-pairs (SP) score.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> : { 1, 2, 3 }</p>
<blockquote>
<div><p>Indicate, which mode to compute. Select between:</p>
<ol class="arabic simple">
<li><p>divide the number of common residue pairs in reference and test
alignment by the total number of residue pairs in the test
alignment (the traditional SP score described in
<code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>, also known as “precision” score in
applications of information retrieval),</p></li>
<li><p>divide the number of common residue pairs in reference and test
alignment by the total number of residue pairs in the reference
alignment (also known as “recall” score in applications of
information retrieval),</p></li>
<li><p>divide the number of common residue pairs in reference and test
alignment by the average number of residue pairs in reference
and test alignment.</p></li>
</ol>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> : float</p>
<blockquote>
<div><p>The SP score for gold standard and test alignments.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The SP score (see <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>) is calculated by dividing the number of
identical residue pairs in reference and test alignment by the total
number of residue pairs in the reference alignment.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingpy.evaluate.apa.EvalPSA">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">lingpy.evaluate.apa.</span></code><code class="sig-name descname"><span class="pre">EvalPSA</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingpy.evaluate.apa.Eval" title="lingpy.evaluate.apa.Eval"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingpy.evaluate.apa.Eval</span></code></a></p>
<p>Base class for the evaluation of automatic pairwise sequence analyses.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>gold, test</strong> : <a class="reference internal" href="lingpy.align.html#lingpy.align.sca.PSA" title="lingpy.align.sca.PSA"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingpy.align.sca.PSA</span></code></a></p>
<blockquote>
<div><p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">Pairwise</span></code> objects which shall be
compared. The first object should be the gold standard and the second
object should be the test set.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Moste of the scores which can be calculated with help of this class are standard
evaluation scores in evolutionary biology. For a close description on how
these scores are calculated, see, for example, <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>,
<code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2012"><span class="pre">List2012</span></a></code>, and <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Rosenberg2009b"><span class="pre">Rosenberg2009b</span></a></code>.</p>
<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalPSA.c_score">
<code class="sig-name descname"><span class="pre">c_score</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.c_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate column (C) score.</p>
<dl class="field-list">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>score</strong> : float</p>
<blockquote>
<div><p>The C score for reference and test alignments.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The C score, as it is described in <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>, is calculated by
dividing the number of columns which are identical in the gold
standarad and the test alignment by the total number of columns in the
test alignment.</p>
</dd></dl>

<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalPSA.diff">
<code class="sig-name descname"><span class="pre">diff</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">keywords</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.diff" title="Permalink to this definition">¶</a></dt>
<dd><p>Write all differences between two sets to a file.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filename</strong> : str (default=’eval_psa_diff’)</p>
<blockquote>
<div><p>Default</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalPSA.jc_score">
<code class="sig-name descname"><span class="pre">jc_score</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.jc_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Jaccard (JC) score.</p>
<dl class="field-list">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>score</strong> : float</p>
<blockquote>
<div><p>The JC score.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The Jaccard score (see <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2012"><span class="pre">List2012</span></a></code>) is calculated by dividing the size of
the intersection of residue pairs in reference and test alignment by
the size of the union of residue pairs in reference and test alignment.</p>
</dd></dl>

<dl class="py attribute">
<dt id="lingpy.evaluate.apa.EvalPSA.pairwise_column_scores">
<code class="sig-name descname"><span class="pre">pairwise_column_scores</span></code><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.pairwise_column_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the different column scores for pairwise alignments. The method
returns the precision, the recall score, and the f-score, following the
proposal of Bergsma and Kondrak (2007), and the column score proposed
by Thompson et al. (1999).</p>
</dd></dl>

<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalPSA.r_score">
<code class="sig-name descname"><span class="pre">r_score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.r_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the percentage of identical rows (PIR) score.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> : { 1, 2 }</p>
<blockquote>
<div><p>Select between mode <code class="docutils literal notranslate"><span class="pre">1</span></code>, where all sequences are compared with
each other, and mode <code class="docutils literal notranslate"><span class="pre">2</span></code>, where only whole alignments are
compared.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> : float</p>
<blockquote>
<div><p>The PIR score.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The PIR score is the number of identical rows (sequences) in reference and test
alignment divided by the total number of rows.</p>
</dd></dl>

<dl class="py method">
<dt id="lingpy.evaluate.apa.EvalPSA.sp_score">
<code class="sig-name descname"><span class="pre">sp_score</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.sp_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the sum-of-pairs (SP) score.</p>
<dl class="field-list">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>score</strong> : float</p>
<blockquote>
<div><p>The SP score for reference and test alignments.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The SP score (see <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>) is calculated by dividing the number of
identical residue pairs in reference and test alignment by the total
number of residue pairs in the reference alignment.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-lingpy.evaluate">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-lingpy.evaluate" title="Permalink to this headline">¶</a></h2>
<p>Basic module for the evaluation of algorithms.</p>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/lingpy.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">lingpy.evaluate package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-lingpy.evaluate.acd">lingpy.evaluate.acd module</a></li>
<li><a class="reference internal" href="#module-lingpy.evaluate.alr">lingpy.evaluate.alr module</a></li>
<li><a class="reference internal" href="#module-lingpy.evaluate.apa">lingpy.evaluate.apa module</a></li>
<li><a class="reference internal" href="#module-lingpy.evaluate">Module contents</a></li>
</ul>
</li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/reference/lingpy.evaluate.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="../index.html">Home</a> |&nbsp;</li>
	<li><a href="../news.html">News</a> |&nbsp;</li>
	<li><a href="../intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="../examples.html">Examples</a> |&nbsp;</li>
	<li><a href="../tutorial/index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="../docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="modules.html">Reference</a> |&nbsp;</li>
  <li><a href="../download.html">Download</a></li>

        <li class="nav-item nav-item-this"><a href="">lingpy.evaluate package</a></li> 
      </ul>
    </div>
 <div id="footer" style="align-items:center;padding-top:5px;padding-left:0px;display:flex;justify-content:space-between;">

   <div>
     <a href="http://shh.mpg.de"><img width="60px" src="../_static/minerva.png" alt="MPG-SSH" /></a>
   </div>
  <div>
    <a href="http://dfg.de/"><img width="80px" src="../_static/dfg_logo_schwarz.jpg" alt="DFG" /></a>
  </div>

  <div style="max-width:300px;">
    <p style="font-size:70%">Created using <a href="http://sphinx-doc.org">Sphinx</a>. Last updated
    on Mar 22, 2021<br>
      This work is licensed under a <a rel="license"
        href="http://creativecommons.org/licenses/by/4.0/">Creative
      Commons Attributio 4.0 International License</a>.</p>
    <p>
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
        <img alt="Creative Commons License" style="border-width:0;width:100px;"
		    src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> </p>
  </div>

  <div>
    <a href="http://erc.europa.eu/"><img width="80px" src="../_static/European_Research_Council_logo.svg" alt="ERC" /></a>
  </div>
  <div style="max-width:150px;text-align:right;">
    <a href="http://github.com/lingpy/lingpy/">Application source on</a> 
    <a href="https://github.com/"><img width="100px" src="../_static/GitHub_Logo.png" alt="github logo" /></a>
</div>
</div>

  </body>
</html>