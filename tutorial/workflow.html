
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Workflow Example &#8212; LingPy</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/lingpy.css" type="text/css" />
    
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<link rel="stylesheet" type="text/css" href="_static/handheld.css" media="screen and (max-device-width: 720px)" />
<style>
li.nav-item{display: None!important};
</style>

  </head><body>
<div style="color: black;background-color: white; font-size: 3.2em; text-align: left; padding: 15px 10px 10px 15px">
LingPy
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="../index.html">Home</a> |&nbsp;</li>
	<li><a href="../news.html">News</a> |&nbsp;</li>
	<li><a href="../intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="../examples.html">Examples</a> |&nbsp;</li>
	<li><a href="index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="../docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="../reference/modules.html">Reference</a> |&nbsp;</li>
  <li><a href="../download.html">Download</a></li>

        <li class="nav-item nav-item-this"><a href="">Workflow Example</a></li> 
      </ul>
    </div>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="workflow-example">
<h1>Workflow Example<a class="headerlink" href="#workflow-example" title="Permalink to this headline">¶</a></h1>
<p>This is an example workflow that illustrates some of the functionality of LingPy. We will use a
small dataset by <code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Kessler2001"><span class="pre">Kessler2001</span></a></code> in order to illustrate how to get from word list data to
aligned cognate sets.</p>
<p>We start by loading the data, which is located in LingPy’s test suite, and can be accessed with help
of the <code class="xref py py-class docutils literal notranslate"><span class="pre">test_data</span></code> function. We use this function to load the file <cite>KSL.qlc</cite> (it provides the exact path to the file), and load the file as a <a class="reference internal" href="../reference/lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal notranslate"><span class="pre">LexStat</span></code></a> object:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.tests.util</span> <span class="kn">import</span> <span class="n">test_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span> <span class="o">=</span> <span class="n">LexStat</span><span class="p">(</span><span class="n">test_data</span><span class="p">(</span><span class="s1">&#39;KSL.qlc&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>After we loaded the data, which is given in the general LingPy format for wordlists (see
<a class="reference internal" href="lingpy.basic.wordlist.html"><span class="doc">Handling Wordlists</span></a> for details), we can access some of its basic statistics, which are
provided by the <a class="reference internal" href="../reference/lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal notranslate"><span class="pre">Wordlist</span></code></a> class upon which the LexStat class is
based, like width (number of languages), or height (number of concepts), or length (number of words):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">lex</span><span class="o">.</span><span class="n">height</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lex</span><span class="p">)</span>
<span class="go">(7, 200, 1400)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">cols</span>
<span class="go">[&#39;Albanian&#39;, &#39;English&#39;, &#39;French&#39;, &#39;German&#39;, &#39;Hawaiian&#39;, &#39;Navajo&#39;, &#39;Turkish&#39;]</span>
</pre></div>
</div>
<p>We can also determine the coverage, which is a dictionary with language name as key and number of
concepts as value:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">coverage</span><span class="p">()</span>
<span class="go">{&#39;Albanian&#39;: 200,</span>
<span class="go"> &#39;English&#39;: 200,</span>
<span class="go"> &#39;French&#39;: 200,</span>
<span class="go"> &#39;German&#39;: 200,</span>
<span class="go"> &#39;Hawaiian&#39;: 200,</span>
<span class="go"> &#39;Navajo&#39;: 200,</span>
<span class="go"> &#39;Turkish&#39;: 200}</span>
</pre></div>
</div>
<p>Let’s start and search for cognates now. If all works fine, and your data is in plain IPA (without
any strange characters and erros), this should work out of the box. However, if you encounter
difficulties, we recommend to make an explicit check by loading the LexStat object with the
check-keyword set to <strong>True</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span> <span class="o">=</span> <span class="n">LexStat</span><span class="p">(</span><span class="n">test_data</span><span class="p">(</span><span class="s1">&#39;KSL.qlc&#39;</span><span class="p">),</span> <span class="n">check</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>If the class is loaded normally, this means, your data is fine. But now let’s start with cognate
judgments, and let’s try the LexStat algorithm (<code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2014d"><span class="pre">List2014d</span></a></code>), which derives individual scorers for all language
pairs based on randomized alignments. In order to use LexStat, we first need to compute the scorer. There are many parameters, but let’s just stick to defaults for now:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">get_scorer</span><span class="p">()</span>
</pre></div>
</div>
<p>Once this is done, we can compute the cognate sets. Here, we should tell LingPy in which column they
should be stored, so we pass the keyword argument “ref” and specify it as “cognates”. We also need
to pass a threshold. Here, for the LexStat method, a threshold of 0.6 normally works quite well:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;lexstat&quot;</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="s2">&quot;cognates&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, we could already write the data to file, where we choose “tsv” as fileformat and specify
“KSL_new” as our filename:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="s1">&#39;tsv&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;KSL_new&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This resulting output file will be very large, since it contains all parameters and the computed
scoring functions for all language pairs. If you want to avoid that and only have the raw TSV
format, specify the “ignore” keyword and set “prettify” to “False”:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="s1">&#39;tsv&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;KSL_new&quot;</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="n">prettify</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>How well was this automatic cognate detection? Let’s test it by computing the B-Cubed scores
(<code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Bagga1999"><span class="pre">Bagga1999</span></a></code>). These rank between 0 and 1, with one being good and 0 being bad, and come in
three flavors of precision (amount of false positives), recall (amount of false negatives) and
F-Score (combined score). We compute them by passing the wordlist object, the gold standard (stored
in column “cogid” in our “KSL.qlc” file), and our computed cognate sets (stored in “cognates”, as we
specified using the “ref” keyword):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.evaluate.acd</span> <span class="kn">import</span> <span class="n">bcubes</span><span class="p">,</span> <span class="n">diff</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bcubes</span><span class="p">(</span><span class="n">lex</span><span class="p">,</span> <span class="s2">&quot;cogid&quot;</span><span class="p">,</span> <span class="s2">&quot;cognates&quot;</span><span class="p">)</span>
<span class="go">*************************&#39;</span>
<span class="go">* B-Cubed-Scores        *</span>
<span class="go">* --------------------- *</span>
<span class="go">* Precision:     0.9293 *</span>
<span class="go">* Recall:        0.9436 *</span>
<span class="go">* F-Scores:      0.9364 *</span>
<span class="go">*************************&#39;</span>
<span class="go">(0.9292857142857142, 0.9435714285714284, 0.9363740873923939)</span>
</pre></div>
</div>
<p>As we can see, the score is rather high, but we should keep in mind that the dataset is rather
small. Note that the scores may differ on your computer, since LexStat shuffles the word lists to
create a random distribution. Normally, however, the differences should not be too huge.</p>
<p>Now that we know that our data has been properly analyzed with good cognate scores, lets align it,
using the <a class="reference internal" href="../reference/lingpy.align.html#lingpy.align.sca.Alignments" title="lingpy.align.sca.Alignments"><code class="xref py py-class docutils literal notranslate"><span class="pre">Alignments</span></code></a> class. We can directly initialize it from the
LexStat object, but we need to pass the “cognates” column as “ref” (this tells LingPy, where to
search for cognate sets which are then multiply aligned), and then, we call the function
<a class="reference internal" href="../reference/lingpy.align.html#lingpy.align.sca.Alignments.align" title="lingpy.align.sca.Alignments.align"><code class="xref py py-class docutils literal notranslate"><span class="pre">align</span></code></a>, using the defaults for convenience:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">alm</span> <span class="o">=</span> <span class="n">Alignments</span><span class="p">(</span><span class="n">lex</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="s1">&#39;cognates&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alm</span><span class="o">.</span><span class="n">align</span><span class="p">()</span>
</pre></div>
</div>
<p>If you want to see the results of this analysis, you need to write them to file. But there, it is
also difficult to see the alignments, since they are in a TSV-file in just another column, called
“alignment” as a default. Another possibility is to write data to HTML format instead. This means
you can’t re-import the data into LingPy, but you can inspect the results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">alm</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="s1">&#39;html&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;KSL&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will create the file <a class="reference external" href="examples/KSL.html">KSL.html</a> which you can inspect by loading it in your webbrowser.</p>
<p>Finally, let’s make a tree of the data. This is very straightforward by passing the “cognates”
column as a reference to the <a class="reference internal" href="../reference/lingpy.basic.html#lingpy.basic.wordlist.Wordlist.calculate" title="lingpy.basic.wordlist.Wordlist.calculate"><code class="xref py py-class docutils literal notranslate"><span class="pre">calculate</span></code></a> function. Printing of the resulting “tree” which is
created as an attribute of the LexStat object, is possible with help of LingPy’s
<a class="reference internal" href="../reference/lingpy.basic.html#lingpy.basic.tree.Tree" title="lingpy.basic.tree.Tree"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tree</span></code></a> class:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">calculate</span><span class="p">(</span><span class="s1">&#39;tree&#39;</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="s1">&#39;cognates&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">lex</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">asciiArt</span><span class="p">())</span>
<span class="go">          /-Hawaiian</span>
<span class="go">         |</span>
<span class="go">-root----|          /-Turkish</span>
<span class="go">         |         |</span>
<span class="go">          \edge.4--|          /-Navajo</span>
<span class="go">                   |         |</span>
<span class="go">                    \edge.3--|                    /-English</span>
<span class="go">                             |          /edge.0--|</span>
<span class="go">                             |         |          \-German</span>
<span class="go">                              \edge.2--|</span>
<span class="go">                                       |          /-Albanian</span>
<span class="go">                                        \edge.1--|</span>
<span class="go">                                                  \-French</span>
</pre></div>
</div>
<p>Well, given that there are unrelated languages in our sample, we should be careful with any
interpretations here, but let’s at least be glad that the algorithm did cluster the Indo-European
languages all together.</p>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/lingpy.png" alt="Logo"/>
            </a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/tutorial/workflow.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="../index.html">Home</a> |&nbsp;</li>
	<li><a href="../news.html">News</a> |&nbsp;</li>
	<li><a href="../intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="../examples.html">Examples</a> |&nbsp;</li>
	<li><a href="index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="../docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="../reference/modules.html">Reference</a> |&nbsp;</li>
  <li><a href="../download.html">Download</a></li>

        <li class="nav-item nav-item-this"><a href="">Workflow Example</a></li> 
      </ul>
    </div>
 <div id="footer" style="align-items:center;padding-top:5px;padding-left:0px;display:flex;justify-content:space-between;">

   <div>
     <a href="http://shh.mpg.de"><img width="60px" src="../_static/minerva.png" alt="MPG-SSH" /></a>
   </div>
  <div>
    <a href="http://dfg.de/"><img width="80px" src="../_static/dfg_logo_schwarz.jpg" alt="DFG" /></a>
  </div>

  <div style="max-width:300px;">
    <p style="font-size:70%">Created using <a href="http://sphinx-doc.org">Sphinx</a>. Last updated
    on Mar 22, 2021<br>
      This work is licensed under a <a rel="license"
        href="http://creativecommons.org/licenses/by/4.0/">Creative
      Commons Attributio 4.0 International License</a>.</p>
    <p>
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
        <img alt="Creative Commons License" style="border-width:0;width:100px;"
		    src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> </p>
  </div>

  <div>
    <a href="http://erc.europa.eu/"><img width="80px" src="../_static/European_Research_Council_logo.svg" alt="ERC" /></a>
  </div>
  <div style="max-width:150px;text-align:right;">
    <a href="http://github.com/lingpy/lingpy/">Application source on</a> 
    <a href="https://github.com/"><img width="100px" src="../_static/GitHub_Logo.png" alt="github logo" /></a>
</div>
</div>

  </body>
</html>