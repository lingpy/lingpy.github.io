
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Whats New in Version 2.6.4? &#8212; LingPy</title>
    <link rel="stylesheet" href="_static/lingpy.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    
    <link rel="shortcut icon" href="_static/favicon.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
<link rel="stylesheet" type="text/css" href="_static/handheld.css" media="screen and (max-device-width: 720px)" />

  </head><body>
<div style="color: black;background-color: white; font-size: 3.2em; text-align: left; padding: 15px 10px 10px 15px">
LingPy
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="index.html">Home</a> |&nbsp;</li>
	<li><a href="#">News</a> |&nbsp;</li>
	<li><a href="intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="examples.html">Examples</a> |&nbsp;</li>
	<li><a href="tutorial/index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="reference/modules.html">Reference</a> |&nbsp;</li>
        <li><a href="download.html">Download </a> </li>

 
      </ul>
    </div>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="whats-new-in-version-version">
<h1>Whats New in Version 2.6.4?<a class="headerlink" href="#whats-new-in-version-version" title="Permalink to this headline">¶</a></h1>
<p>Version 2.6.4 of LingPy introduces a couple of refinements of LingPy, but it does not introduce
many new algorithms. New algorithms can now mostly be found in additional packages, such as SinoPy
(<a class="reference external" href="https://github.com/lingpy/sinopy">https://github.com/lingpy/sinopy</a>) or LingRex (<a class="reference external" href="https://github.com/lingpy/lingrex">https://github.com/lingpy/lingrex</a>). While SinoPy is a
very specialized package to be used for manipulation of SEA and Chinese language data, LingRex
offers a couple of new algorithms that we may consider including in a future version of LingPy, but
which have not been sufficiently tested to be included right now.</p>
<p>What was introduced in this new version, is a new module to manipulate ngrams and Markov Models (provided by
Tiago Tresoldi) and a new function to import CLDF data with help of the Wordlist class and its
derivatives.</p>
<p>In the following, we list both the new features introduced in version 2.6.3, as well as the new
functions from the new version 2.6.4.</p>
<div class="section" id="loading-cldf-data-from-wordlist-objects-2-6-4">
<h2>Loading CLDF Data from Wordlist Objects (2.6.4)<a class="headerlink" href="#loading-cldf-data-from-wordlist-objects-2-6-4" title="Permalink to this headline">¶</a></h2>
<p>Instead of using the <cite>from_cldf</cite> function, you can now simply use the <cite>Wordlist</cite> class to load a
CLDF dataset:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy</span> <span class="k">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wl</span> <span class="o">=</span> <span class="n">Wordlist</span><span class="o">.</span><span class="n">from_cldf</span><span class="p">(</span><span class="s1">&#39;path/to/metadata/json&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="handling-ngrams-2-6-4">
<h2>Handling Ngrams (2.6.4)<a class="headerlink" href="#handling-ngrams-2-6-4" title="Permalink to this headline">¶</a></h2>
<p>This module offers a general class to handle Markov Models and many utility functions for the
manipulation of ngrams:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.sequence.ngrams</span> <span class="k">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">get_n_ngrams</span><span class="p">(</span><span class="s1">&#39;LingPy&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">[(&#39;$$$&#39;, &#39;$$$&#39;, &#39;$$$&#39;, &#39;L&#39;),</span>
<span class="go"> (&#39;$$$&#39;, &#39;$$$&#39;, &#39;L&#39;, &#39;i&#39;),</span>
<span class="go"> (&#39;$$$&#39;, &#39;L&#39;, &#39;i&#39;, &#39;n&#39;),</span>
<span class="go"> (&#39;L&#39;, &#39;i&#39;, &#39;n&#39;, &#39;g&#39;),</span>
<span class="go"> (&#39;i&#39;, &#39;n&#39;, &#39;g&#39;, &#39;P&#39;),</span>
<span class="go"> (&#39;n&#39;, &#39;g&#39;, &#39;P&#39;, &#39;y&#39;),</span>
<span class="go"> (&#39;g&#39;, &#39;P&#39;, &#39;y&#39;, &#39;$$$&#39;),</span>
<span class="go"> (&#39;P&#39;, &#39;y&#39;, &#39;$$$&#39;, &#39;$$$&#39;),</span>
<span class="go"> (&#39;y&#39;, &#39;$$$&#39;, &#39;$$$&#39;, &#39;$$$&#39;)]</span>
</pre></div>
</div>
<p>So as you can see, this function allows you to retrieve as many ngrams from a given string as you
want. The new module also inherits the functions that one could find in the <cite>sound_classes</cite> module
before, including shortcuts for creating bigrams and trigrams.</p>
</div>
<div class="section" id="bugfixes-in-wordlist-class-2-6-3">
<h2>Bugfixes in Wordlist Class (2.6.3)<a class="headerlink" href="#bugfixes-in-wordlist-class-2-6-3" title="Permalink to this headline">¶</a></h2>
<p>We fixed some problems related to the <a class="reference internal" href="reference/lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal notranslate"><span class="pre">Wordlist</span></code></a> class in LingPy. First, if you
make the transition from a Wordlist object to a <a class="reference internal" href="reference/lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal notranslate"><span class="pre">LexStat</span></code></a> object, the data
will be deep-copied. As a result, writing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.tests.util</span> <span class="k">import</span> <span class="n">test_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy</span> <span class="k">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wl</span> <span class="o">=</span> <span class="n">Wordlist</span><span class="p">(</span><span class="n">test_data</span><span class="p">(</span><span class="s1">&#39;KSL.qlc&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span> <span class="o">=</span> <span class="n">LexStat</span><span class="p">(</span><span class="n">wl</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">add_entries</span><span class="p">(</span><span class="s1">&#39;segments&#39;</span><span class="p">,</span> <span class="s1">&#39;tokens&#39;</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="s1">&#39;segments&#39;</span> <span class="ow">in</span> <span class="n">wl</span><span class="o">.</span><span class="n">header</span>
<span class="go">False</span>
</pre></div>
</div>
<p>will no longer add the same number of new entries to the Wordlist object (as it happened before).
You can now also easily access the header of a wordlist in its current order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">wl</span> <span class="o">=</span> <span class="n">Wordlist</span><span class="p">(</span><span class="n">test_data</span><span class="p">(</span><span class="s1">&#39;KSL.qlc&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wl</span><span class="o">.</span><span class="n">columns</span>
<span class="go">[&#39;doculect&#39;, &#39;concept&#39;, &#39;glossid&#39;, &#39;orthography&#39;, &#39;ipa&#39;, &#39;tokens&#39;, &#39;cogid&#39;]</span>
</pre></div>
</div>
<p>This is specifically convenient if you construct a Wordlist by creating a dictionary inside a Python
script.</p>
</div>
<div class="section" id="sanity-checks-of-linguistic-data-2-6-3">
<h2>Sanity Checks of Linguistic Data (2.6.3)<a class="headerlink" href="#sanity-checks-of-linguistic-data-2-6-3" title="Permalink to this headline">¶</a></h2>
<p>We introduce a new module, called <a class="reference internal" href="reference/lingpy.compare.html#module-lingpy.compare.sanity" title="lingpy.compare.sanity"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sanity</span></code></a>. In this module, we provide a couple of new
functions which you can use to check the consistency of your data. One specific focus, given that
LingPy is focused on sequence comparison, is the <em>coverage</em> of words in a wordlist. Coverage is
hereby understood as the minimal number of words shared per meaning slot in each language pair.
Interestingly, you will notice, when testing certain datasets, that mutual coverage can at times be
extremely low. As a rule of thumb, if your data’s mutual coverage is below 100 for moderately
divergent language samples, you should not run an analysis using the “lexstat” algorithm of the
~lingpy.compare.lexstat.LexStat class, but instead turn to the “sca” method provided by the same
class. Mutual coverage can be computed in a straightforward manner:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.compare.sanity</span> <span class="k">import</span> <span class="n">mutual_coverage_check</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wl</span> <span class="o">=</span> <span class="n">Wordlist</span><span class="p">(</span><span class="n">test_data</span><span class="p">(</span><span class="s1">&#39;KSL.qlc&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">wl</span><span class="o">.</span><span class="n">height</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
<span class="go">        if mutual_coverage_check(wl, i):</span>
<span class="go">            print(&#39;mutual coverage is {0}&#39;.format(i))</span>
<span class="go">            break</span>
<span class="go">    200</span>
</pre></div>
</div>
<p>We highly recommend all users which deal with spotty and patchy data to have a closer look at the
coverage functions offered in the <a class="reference internal" href="reference/lingpy.compare.html#module-lingpy.compare.sanity" title="lingpy.compare.sanity"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sanity</span></code></a> module. You may also want to check out the
<a class="reference internal" href="reference/lingpy.compare.html#lingpy.compare.sanity.synonymy" title="lingpy.compare.sanity.synonymy"><code class="xref py py-func docutils literal notranslate"><span class="pre">synonymy()</span></code></a> function which computes the number of synonyms in your dataset. Here
again, we recommend to pay specific attention to not exceed a value of maximally three words per
concept and language.</p>
</div>
<div class="section" id="alignments-and-cognate-sets-2-6-3">
<h2>Alignments and Cognate Sets (2.6.3)<a class="headerlink" href="#alignments-and-cognate-sets-2-6-3" title="Permalink to this headline">¶</a></h2>
<p>This is again a small change, but to allow for a more consistent integration with external tools, we
now allow to use the cognate set identifier “0” to account for cases where not decision has yet been
made. That means, if you assign cognate sets IDs (“COGID”) to your data, and one is set to “0”, this
won’t be aligned, and not clustered together with other words which have identifier “0”.</p>
</div>
<div class="section" id="random-clusters-lumper-and-splitter-2-6-3">
<h2>Random Clusters, Lumper, and Splitter (2.6.3)<a class="headerlink" href="#random-clusters-lumper-and-splitter-2-6-3" title="Permalink to this headline">¶</a></h2>
<p>We added a new experimental module, in which we added a couple of functions that help to deal with
random clusters. The module <a class="reference internal" href="reference/lingpy.algorithm.html#module-lingpy.algorithm.cluster_util" title="lingpy.algorithm.cluster_util"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cluster_util</span></code></a> offers ways to mutate a given cluster, to
create a random cluster, or to create all possible clusters for a given size of entities. This
module was originally prepared to allow to add random cognate sets to a wordlist in order to compare
this random output with non-random algorithms for cognate detection:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.evaluate.acd</span> <span class="k">import</span> <span class="n">random_clusters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">random_clusters</span><span class="p">(</span><span class="n">wl</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="s2">&quot;randomid&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We then figured that it would also be interesting to compare random clusters with “extreme”
clusters, namely, the clusters provided by “lumpers” and “splitters”. Thus, we added another custom
function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.evaluate.acd</span> <span class="k">import</span> <span class="n">extreme_clusters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">extreme_clusters</span><span class="p">(</span><span class="n">wl</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="s1">&#39;lumperid&#39;</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="s1">&#39;lumper&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>If you carry out an assessment of cognate detection algorithms of your data, we recommend to always
compare those against the lumper and the splitter, as this can already tell you a lot about the
nature of your data. In some datasets, the lumper will receive evaluation scores of more than 73%,
only because the cognate density is so high in the data. This means in turn, if your algorithm does
not perform much better than 73% in these cases, it does not mean that it is performing quite well.</p>
</div>
<div class="section" id="adding-support-to-read-cldf-2-6-3">
<h2>Adding Support to Read CLDF (2.6.3)<a class="headerlink" href="#adding-support-to-read-cldf-2-6-3" title="Permalink to this headline">¶</a></h2>
<p>The cross-linguistic data formats (<a class="reference external" href="http://cldf.clld.org">CLDF</a>) initiative (<code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Forkel2017a"><span class="pre">Forkel2017a</span></a></code>)
provides standardized formats for wordlists and cognate judgments. The <a class="reference external" href="http://github.com/cldf/pycldf">pycldf</a> package provides support to convert LingPy-formatted data sets
into CLDF format. LingPy now also provides support to read CLDF-files and convert them into
~lingpy.basic.wordlist.Wordlist objects:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">wl</span> <span class="o">=</span> <span class="n">Wordlist</span><span class="p">(</span><span class="n">test_data</span><span class="p">(</span><span class="s1">&#39;KSL.qlc&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.convert.cldf</span> <span class="k">import</span> <span class="n">to_cldf</span><span class="p">,</span> <span class="n">from_cldf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">to_cldf</span><span class="p">(</span><span class="n">wl</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wl</span> <span class="o">=</span> <span class="n">from_cldf</span><span class="p">(</span><span class="s1">&#39;cldf/Wordlist-metadata.json&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="adding-nexus-output-2-6-3">
<h2>Adding Nexus Output (2.6.3)<a class="headerlink" href="#adding-nexus-output-2-6-3" title="Permalink to this headline">¶</a></h2>
<p>We had nexus output before, but now, Simon Greenhill has helped us to provide a stable export to
both MrBayes and Beast, also including the situation where you want to calculate rates for each
concept class:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">wl</span> <span class="o">=</span> <span class="n">Wordlist</span><span class="p">(</span><span class="n">test_data</span><span class="p">(</span><span class="s2">&quot;KSL.qlc&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.convert.strings</span> <span class="k">import</span> <span class="n">write_nexus</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mb</span> <span class="o">=</span> <span class="n">write_nexus</span><span class="p">(</span><span class="n">wl</span><span class="p">,</span> <span class="s1">&#39;mrbayes&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;ksl-mrbayes.nex&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">beast</span> <span class="o">=</span> <span class="n">write_nexus</span><span class="p">(</span><span class="n">wl</span><span class="p">,</span> <span class="s1">&#39;beastwords&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;ksl-beast.nex&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="orthography-profile-creation-2-6-3">
<h2>Orthography Profile Creation (2.6.3)<a class="headerlink" href="#orthography-profile-creation-2-6-3" title="Permalink to this headline">¶</a></h2>
<p>We introduced the commandline of LingPy in version 2.5, but have not really worked on it since then,
as we think that cognate detection analyses should not go on silent by just typing a command into
the terminal. Instead, we encourage users to learn what the major algorithms are, and how they
should be used. We also recommend you to have a look at an <a class="reference external" href="https://github.com/shh-dlce/qmss-2017/tree/master/LingPy">online tutorial</a> which Johann-Mattis List prepared early in 2017. However, in one particular cases, the commandline actually proved to be very useful, and this is for the creation of orthography profiles (<code class="docutils literal notranslate"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Moran2017"><span class="pre">Moran2017</span></a></code>).
Thus, if you now have a normal LingPy wordlist, you can preparse it with LingPy to create an initial
(hopefully useful) orthography profile, via the commandline:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ lingpy profile -i input-file.tsv --column=form --context -o output-profile.tsv
</pre></div>
</div>
<p>If you choose the “—context” option, this means that LingPy will add information on which language
shows which pattern, and whether this occurs in the beginning (“^”) or the end (“$”) of a given
phonetic sequence. More information can also be found in [this](<a class="reference external" href="https://zenodo.org/badge/latestdoi/109654333">https://zenodo.org/badge/latestdoi/109654333</a>) tutorial on LingPy and EDICTOR.</p>
</div>
<div class="section" id="lingpy-cookbook-2-6-3">
<h2>LingPy Cookbook (2.6.3)<a class="headerlink" href="#lingpy-cookbook-2-6-3" title="Permalink to this headline">¶</a></h2>
<p>We decided that we will start introducing LingPy in bits and bytes, since the full reference may at
times overwhel new users. We started collecting some little howtos on our LingPy Cookbook, which you
can fine <a class="reference external" href="https://github.com/lingpy/cookbook">here</a>.</p>
</div>
<div class="section" id="what-s-next">
<h2>What’s Next?<a class="headerlink" href="#what-s-next" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial/index.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="docu/index.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="download.html">Download</a></li>
</ul>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/lingpy.png" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Whats New in Version 2.6.4?</a><ul>
<li><a class="reference internal" href="#loading-cldf-data-from-wordlist-objects-2-6-4">Loading CLDF Data from Wordlist Objects (2.6.4)</a></li>
<li><a class="reference internal" href="#handling-ngrams-2-6-4">Handling Ngrams (2.6.4)</a></li>
<li><a class="reference internal" href="#bugfixes-in-wordlist-class-2-6-3">Bugfixes in Wordlist Class (2.6.3)</a></li>
<li><a class="reference internal" href="#sanity-checks-of-linguistic-data-2-6-3">Sanity Checks of Linguistic Data (2.6.3)</a></li>
<li><a class="reference internal" href="#alignments-and-cognate-sets-2-6-3">Alignments and Cognate Sets (2.6.3)</a></li>
<li><a class="reference internal" href="#random-clusters-lumper-and-splitter-2-6-3">Random Clusters, Lumper, and Splitter (2.6.3)</a></li>
<li><a class="reference internal" href="#adding-support-to-read-cldf-2-6-3">Adding Support to Read CLDF (2.6.3)</a></li>
<li><a class="reference internal" href="#adding-nexus-output-2-6-3">Adding Nexus Output (2.6.3)</a></li>
<li><a class="reference internal" href="#orthography-profile-creation-2-6-3">Orthography Profile Creation (2.6.3)</a></li>
<li><a class="reference internal" href="#lingpy-cookbook-2-6-3">LingPy Cookbook (2.6.3)</a></li>
<li><a class="reference internal" href="#what-s-next">What’s Next?</a></li>
</ul>
</li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/news.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="index.html">Home</a> |&nbsp;</li>
	<li><a href="#">News</a> |&nbsp;</li>
	<li><a href="intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="examples.html">Examples</a> |&nbsp;</li>
	<li><a href="tutorial/index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="reference/modules.html">Reference</a> |&nbsp;</li>
        <li><a href="download.html">Download </a> </li>

 
      </ul>
    </div>
 <div id="footer" style="align-items:center;padding-top:5px;padding-left:0px;display:flex;justify-content:space-between;">

   <div>
     <a href="http://shh.mpg.de"><img width="60px" src="_static/minerva.png" alt="MPG-SSH" /></a>
   </div>
  <div>
    <a href="http://dfg.de/"><img width="80px" src="_static/dfg_logo_schwarz.jpg" alt="DFG" /></a>
  </div>

  <div style="max-width:300px;">
    <p style="font-size:70%">Created using <a href="http://sphinx-doc.org">Sphinx</a>. Last updated
    on Nov 25, 2018<br>
      This work is licensed under a <a rel="license"
        href="http://creativecommons.org/licenses/by/4.0/">Creative
      Commons Attributio 4.0 International License</a>.</p>
    <p>
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
        <img alt="Creative Commons License" style="border-width:0;width:100px;"
		    src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> </p>
  </div>

  <div>
    <a href="http://erc.europa.eu/"><img width="80px" src="_static/European_Research_Council_logo.svg" alt="ERC" /></a>
  </div>
  <div style="max-width:150px;text-align:right;">
    <a href="http://github.com/lingpy/lingpy/">Application source on</a> 
    <a href="https://github.com/"><img width="100px" src="_static/GitHub_Logo.png" alt="github logo" /></a>
</div>
</div>

  </body>
</html>